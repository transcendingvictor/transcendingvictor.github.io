<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Your Name - Home</title>
    <link rel="stylesheet" href="resources/css/style.css">
    <script>
        function loadSidebar() {
            fetch("resources/sidebar.html")
                .then(response => response.text())
                .then(data => {
                    document.getElementById("sidebar-container").innerHTML = data;
                });
        }
    </script>
</head>
<body onload="loadSidebar()">

    <!-- Sidebar Placeholder -->
    <div id="sidebar-container"></div>

    <!-- Main Content -->
    <div class="main-content">
        <h1>About</h1>

        <p>
            Hey! I’m Víctor, a 1st-year PhD student at CitAI research lab (https://cit-ai.net/)  at City St George’s, University of London.
             Currently, I’m working on the specific problem of Value System Aggregation under the supervision of Marc Serramia Amoros (link) and Eduardo Alonso (link).
              My next steps involve exploring the question of what values should intellegent autonomous systems align to with the goal of enusring a safe and ethical AI development.
              Yet, my interests expand the following topics:
        </p>
                
        <ul>
          <li> Collective decision making processes like liquid democracy, participatory budgeting and the role of deliberation; also, collective intelligence. </li>
          <li> Modelling ethical decision-making via value systems, and how can we obtain such value systems</li>
          <li> The intersection between game theory, multiagent systems and cooperative AI.  </li>
          <li> The alignment problem (in AI and democratic contexts) and the control problem. </li>

        </ul>


        <h2>Studies</h2>
        <p> I hold a BSc in Mathematics with Economics from University College London and an MSc in Artificial Intelligence, where I earned distinction (85%) for my dissertation.
             Currently, I'm pursuing a PhD at the CitAI Research Centre in London, funded by a UKRI EPSRC Scholarship.

            Beyond my studies, I received a grant from Open Philanthropy to foster a community around existential risks among London university students. 
            I’ve also collaborated on research projects with the Oxford AI Safety Hub Labs 2023 and the AI Safety Camp 2024. Additionally, I participated in the
             Machine Learning Safety Scholar (MLSS) summer program in 2022 and the Topics in Economic Theory & Global Prioritization summer program (led by Phillip Tramell) in 2023.</p>

        <h2>PhD Research</h2>
        
        <p>
            Values are the abstract motivations that drive our opinions and actions, yet it is difficult to fully conceptualize what out values exactly are. At the same time, as AI systems gain autonomy, it becomes increasingly urgent to computationally capture what we want, ensuring they align with human intentions. This raises a fundamental question in AI alignment: how can we guarantee that AI systems act in accordance with human moral values?
        </p>
        <p>
            My research focuses on value inference—the mathematical formalization of moral values to guide collective systems, from superintelligent AIs to political institutions, toward decisions that reflect the principles of the people they represent. By developing rigorous frameworks for extracting and structuring these values, I aim to contribute to the safe and ethically sound deployment of AI in high-stakes domains. Recently, my work has centered on value system aggregation and how to determine the values of a group, rather than an individual. By developing rigorous frameworks for extracting and structuring these values, I aim to contribute to the safe and ethically grounded deployment of AI in high-stakes domains.
          </p>

        <p>Feel free to reach out if you'd like to collaborate or discuss research ideas.</p>
    </div>

</body>
</html>
