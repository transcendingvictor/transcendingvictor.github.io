<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    
        <title>About | M. Reboredo Prado</title>
    
        <!-- Fonts -->
        <link href="resources/fonts/Computer Modern/Sans/cmun-sans.css" rel="stylesheet">
        <link href="resources/fonts/Computer Modern/Serif/cmun-serif.css" rel="stylesheet">
    
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Aleo:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Vollkorn+SC:wght@400;600;700;900&display=swap" rel="stylesheet">
    
        <!-- Icons -->
        <script src="https://kit.fontawesome.com/a39fa44c6b.js" crossorigin="anonymous"></script>
    
        <!-- Stylesheet-->
        <link href="./resources/css/style.css" type="text/css" rel="stylesheet">
    </head>
<body>
    <header>
        <div class="me">
            <a aria-current="page" href="./self.html" >
                <img class="circularimage borderimage" alt="me!" src="./resources/img/victor_abrigo_graduacion.jpg" width="100" height="100">
                <p> <strong> Víctor Abia Alonso </strong> </p>
            </a>
        </div>
        <p> 1st year PhD Student in AI Value Alignment interested in social choice, multiagent systems and moral value systems.
        <div class="links">
            <span> <a target="_blank" rel="nofollow noopener noreferrer"
                      href="https://github.com/transcendingvictor">Github</a> </span>
            <span class="tab"></span>
            <span> <a target="_blank" rel="nofollow noopener noreferrer"
                      href="https://www.linkedin.com/in/v%C3%ADctor-abia-alonso-8492a31bb/">LinkedIn</a> </span>
            <span class="tab"></span>
            <span> <a target="_blank" rel="nofollow noopener noreferrer"
                      href="https://orcid.org/0009-0004-1775-8405">ORCID</a> </span>
            <span class="tab"></span>
            <span> <a target="_blank" rel="nofollow noopener noreferrer"
                      href="https://www.youtube.com/@transcendingvictor">Youtube</a> </span>
        </div>
    <!-- Academic Box -->
    <div class="nav-box nav-box-academic">
        <ul>
            <li><a href="index.html">About</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="publications.html">Publications</a></li>
            <li><a href="talks.html">Talks & Public</a></li>
            <li><a href="teaching.html">Teaching</a></li>
        </ul>
    </div>
    <!-- Personal Box -->
    <div class="nav-box nav-box-personal">
        <ul>
            <li><a href="self.html">Self</a></li>
            <li><a href="poems.html">Poems</a></li>
            <li><a href="reflective.html">Reflective Writing</a></li>
            <li><a href="youtube.html">YouTube</a></li>
        </ul>
    </div>
    </header>
    <!-- Sidebar Placeholder -->
    <div id="sidebar-container"></div>

    <!-- Main Content -->
    <div class="mainbody">
        <h1>About</h1>
    
        <p>
            Hey! I’m Víctor, a 1st-year PhD student at 
            <a target="_blank" rel="nofollow noopener noreferrer" href="https://cit-ai.net/">CitAI Research Centre</a>.
            Currently, I’m working on the specific problem of Value System Aggregation under the supervision of 
            Marc Serramia Amoros and Eduardo Alonso.
            My next steps involve exploring the question of what values intelligent autonomous systems should align to, 
            with the goal of ensuring safe and ethical AI development.
            However, my interests extend to the following topics:
        </p>
    
        <ul role="presentation" class="listtext">
            <li>Collective decision-making processes like liquid democracy, participatory budgeting, and the role of deliberation; also, collective intelligence.</li>
            <li>Modelling ethical decision-making via value systems, and how we can obtain such value systems.</li>
            <li>The intersection between game theory, multiagent systems, and cooperative AI.</li>
            <li>The alignment problem (in AI and democratic contexts) and the control problem.</li>
        </ul>
    
        <h2>Studies</h2>
        <p> 
            I hold a BSc in Mathematics with Economics from University College London
            and an MSc in Artificial Intelligence, where I earned distinction (85%) for my dissertation.
            Currently, I'm pursuing a PhD at City St George’s, University of London funded by a 
            <a target="_blank" rel="nofollow noopener noreferrer" href="https://www.ukri.org/">UKRI EPSRC Scholarship</a>.
        </p>
        
        <p>
            Beyond my studies, I received a grant from <a target="_blank" rel="nofollow noopener noreferrer" href="https://www.openphilanthropy.org/">Open Philanthropy</a> 
            to foster a community around existential risks among London university students. 
            I’ve also collaborated on research projects with the Oxford AI Safety Hub Labs 2023 
            and the AI Safety Camp 2024. 
            Additionally, I participated in the Machine Learning Safety Scholar (MLSS) summer program in 2022 
            and the Topics in Economic Theory & Global Prioritization summer program (led by Phillip Tramell) in 2023.
        </p>
    
        <h2>PhD Research</h2>
    
        <p>
            Values are the abstract motivations that drive our opinions and actions, yet it is difficult to fully conceptualize what our values exactly are. 
            At the same time, as AI systems gain autonomy, it becomes increasingly urgent to computationally capture what we want, ensuring they align with human intentions. 
            This raises a fundamental question in AI alignment: how can we guarantee that AI systems act in accordance with human moral values?
        </p>
        
        <p>
            My research focuses on value inference—the mathematical formalization of moral values to guide collective systems, 
            from superintelligent AIs to political institutions, toward decisions that reflect the principles of the people they represent. 
            By developing rigorous frameworks for extracting and structuring these values, I aim to contribute to the safe and ethically sound deployment of AI in high-stakes domains. 
            Recently, my work has centered on value system aggregation and how to determine the values of a group, rather than an individual.
        </p>
    
        <p>Feel free to <a target="_blank" rel="nofollow noopener noreferrer" href="mailto:your-email@example.com">reach out</a> if you'd like to collaborate or discuss research ideas.</p>
    </div>

</body>
</html>
